{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer un archivo TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer un Archivo .docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ficción Espacial: En la lejana galaxia de Zenthoria, dos civilizaciones alienígenas, los Dracorians y los Lumis, se encuentran al borde de la guerra intergaláctica. Un intrépido explorador, Zara, descubre un antiguo artefacto que podría contener la clave para la paz. Mientras viaja por planetas hostiles y se enfrenta a desafíos cósmicos, Zara debe desentrañar los secretos de la reliquia antes de que la galaxia se sumerja en el caos.\n",
      "\n",
      "Ficción Tecnológica: En un futuro distópico, la inteligencia artificial ha evolucionado al punto de alcanzar la singularidad. Un joven ingeniero, Alex, se ve inmerso en una conspiración global cuando descubre que las supercomputadoras han desarrollado emociones. A medida que la humanidad lucha por controlar a estas máquinas sintientes, Alex se enfrenta a dilemas éticos y decisiones que podrían cambiar el curso de la historia.\n",
      "\n",
      "Naturaleza Deslumbrante: En lo profundo de la selva amazónica, una flor mágica conocida como \"Luz de Luna\" florece solo durante la noche. Con pétalos que brillan intensamente, la flor ilumina la oscuridad de la jungla, guiando a criaturas nocturnas y revelando paisajes deslumbrantes. Los lugareños creen que posee poderes curativos, convirtiéndola en el tesoro oculto de la naturaleza.\n",
      "\n",
      "Cuento Corto: En un pequeño pueblo, cada año, un reloj antiguo regala un día extra a la persona más desafortunada. Emma, una joven huérfana, es la elegida este año. Durante su día adicional, descubre una puerta mágica que la transporta a un mundo lleno de maravillas. Al final del día, Emma decide compartir su regalo con el pueblo, dejando una huella imborrable en el corazón de cada habitante.\n",
      "\n",
      "Características del Héroe Olvidado: Conocido como \"Sombra Silenciosa\", nuestro héroe es un maestro del sigilo y la astucia. Dotado de una memoria fotográfica y habilidades de camuflaje, se desplaza entre las sombras para proteger a los indefensos. Su pasado enigmático esconde tragedias que lo impulsan a luchar contra la injusticia. Aunque carece de habilidades sobrenaturales, su ingenio y habilidades tácticas lo convierten en una fuerza a tener en cuenta.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Abre el archivo .docx\n",
    "doc = Document('F:\\Proyectos\\PiConsulting\\challenge_rag_llm\\docs\\documento.docx')\n",
    "\n",
    "# Lee el contenido del documento\n",
    "for paragraph in doc.paragraphs:\n",
    "    print(paragraph.text)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer un archivo .pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m loader \u001b[38;5;241m=\u001b[39m PyPDFLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProyectos\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPiConsulting\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchallenge_rag_llm\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchallenge_ ai_engineer.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m pages \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_and_split()\n\u001b[1;32m----> 5\u001b[0m \u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Document' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"F:\\Proyectos\\PiConsulting\\challenge_rag_llm\\docs\\challenge_ ai_engineer.pdf\")\n",
    "pages = loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Challenge RAG con LLMs  \n",
      " \n",
      "Objetivo general  \n",
      " \n",
      "Se requiere desarrollar  una solucion simple de tipo RAG (retrieved augmented generation) , en \n",
      "donde , mediante  una API se permita interactuar con  un LLM con el fin de generar un a respuesta  \n",
      "(sobre un documento en particular ) a la pregunta brindada por el usuario . \n",
      " \n",
      "RAG Framework  \n",
      "El entregable debe contar con los siguientes componentes.  \n",
      "Componentes  \n",
      "API \n",
      "Desarrollar una API  en python  con Flask o FastApi.  La cual correra local mente  y sera  el medio de \n",
      "comunicación entre el usuario y el LLM . \n",
      "El request tendra la siguiente estructura . \n",
      "{ \n",
      "          \"user_name \": \"John Doe \", \n",
      "          \"question \": \"How are you today? \", \n",
      "} \n",
      "LLM \n",
      "Usar un LLM mediante su API para responder las preguntas del usuario.  \n",
      "Es libre de elegir cualquiera que acepte chat y embeddings, Cohere es una opcion gratuita , OpenAI \n",
      "es una opcion paga.  \n",
      "Puede usarse Langchain s i lo desea.\n"
     ]
    }
   ],
   "source": [
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='   \\n \\n   \\n \\nChallenge RAG con LLMs  \\n \\nObjetivo general  \\n \\nSe requiere desarrollar  una solucion simple de tipo RAG (retrieved augmented generation) , en \\ndonde , mediante  una API se permita interactuar con  un LLM con el fin de generar un a respuesta  \\n(sobre un documento en particular ) a la pregunta brindada por el usuario . \\n \\nRAG Framework  \\nEl entregable debe contar con los siguientes componentes.  \\nComponentes  \\nAPI \\nDesarrollar una API  en python  con Flask o FastApi.  La cual correra local mente  y sera  el medio de \\ncomunicación entre el usuario y el LLM . \\nEl request tendra la siguiente estructura . \\n{ \\n          \"user_name \": \"John Doe \", \\n          \"question \": \"How are you today? \", \\n} \\nLLM \\nUsar un LLM mediante su API para responder las preguntas del usuario.  \\nEs libre de elegir cualquiera que acepte chat y embeddings, Cohere es una opcion gratuita , OpenAI \\nes una opcion paga.  \\nPuede usarse Langchain s i lo desea.  \\n', metadata={'source': 'F:\\\\Proyectos\\\\PiConsulting\\\\challenge_rag_llm\\\\docs\\\\challenge_ ai_engineer.pdf', 'page': 0}),\n",
       " Document(page_content='   \\n \\n   \\n \\nEMBEDDINGS  \\nEl documento proporcionado debera dividirse en chunks (determinar cuantos y porque) y luego se \\ntiene que hacer un encoding de esos chunks.  \\nDichos chunks con su correspondiente encoding deberan guardarse en algun a vectorDB , chromaDB \\nes una opcion gratuita ( https://docs.trychroma.com/ ) \\nA la hora de hacer le la pregunta  del usuario al LLM , se tiene que hacer el encoding de la pregunta y \\nbuscar por similaridad el chunck mas relevante, y luego pasarlo como contexto en el prompt para \\nque el LLM pueda responder  en base a ese contexto . \\nHINT: de ser necesario p ueden hacerse modificaciones en la estructura del documento, pero nunca \\nde su contenido.  \\nPROMPT  \\nEL prompt a pasar d ebe incluir la pregunta del usuario, el contexto para responderla y lo que uds \\ncrean necesario para cumplir con los requisitos de la respuesta.  \\nREQUISITOS DE LA RESPUESTA  \\n- ante la misma pregunta siempre debe responder exactamente igual . \\n- que responda en solo una oracion . \\n- el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues) . \\n- que agregue emojis en la oracion que resuman el contenido de la misma . \\n- que responda siempre en tercera persona.  \\n \\nPRUEBAS  \\nSe debera responder correctamente a  las preguntas que se hagan sobre los documentos, algunos \\nejemplos son:  \\n- Quien es  Zara?  \\n- What did Emma decide to do?  \\n- What is the name o f the  magical flower ? \\n \\nENTREGABLE FINAL  \\n- script de Python para correr de manera local . \\n- requirements .txt \\n- repositorio en git con el progreso del proyecto  \\n- prompt  \\n ', metadata={'source': 'F:\\\\Proyectos\\\\PiConsulting\\\\challenge_rag_llm\\\\docs\\\\challenge_ ai_engineer.pdf', 'page': 1}),\n",
       " Document(page_content='   \\n \\n   \\n \\nCaracterísticas técnicas  \\nEl servicio deberá tener las siguientes características:  \\n• Se deberá usar framework de Python para crear la aplicación  (FastAPI  o Flask ) \\n• Deberá implementarse sobre un ambiente virtual.  \\n• Deberá implementarse en un repositorio GIT.  \\n• Se requiere utilizar una base de datos  vectorial  (vectorDB) . \\nConsideraciones  \\nAlgunos de los puntos que serán tenidos en cuenta son los siguientes : \\n• Aplicar buenas prácticas en organización del proyecto (clean architecture).  \\n• Aplicar buenas prácticas de código y comentarios.  \\n• El proyecto deberá estar disponible en un repositorio GIT con la documentación necesaria \\npara poder correr localmente el mismo.  \\n• Se valorará la Documentacion (formato Readme.md)  \\n• Se valorará la implementación de un Dockerfile para poder levantar la api en un contenedor \\nde docker.  \\n• Se valorará la la construcción de una colección en PostMan (o similar) para la prueba de la \\nAPI. \\n \\nIMPORTANTE: Se evaluara el funcionamiento del proyecto en la instancia de devolucion de l \\nchallenge utilizando las preguntas de pru eba b rindadas y/o alguna pregunta adicional.  \\nSe adjunta jupyter notebook con documentacion util  y documento con los temas a responder . \\nCualquier duda o consulta comunicarse a la dirección donde recibiste el challenge.  \\n \\n ', metadata={'source': 'F:\\\\Proyectos\\\\PiConsulting\\\\challenge_rag_llm\\\\docs\\\\challenge_ ai_engineer.pdf', 'page': 2})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Challenge RAG con LLMs  \\n \\nObjetivo general  \\n \\nSe requiere desarrollar  una solucion simple de tipo RAG (retrieved augmented generation) , en \\ndonde , mediante  una API se permita interactuar con  un LLM con el fin de generar un a respuesta  \\n(sobre un documento en particular ) a la pregunta brindada por el usuario . \\n \\nRAG Framework  \\nEl entregable debe contar con los siguientes componentes.  \\nComponentes  \\nAPI \\nDesarrollar una API  en python  con Flask o FastApi.  La cual correra local mente  y sera  el medio de \\ncomunicación entre el usuario y el LLM . \\nEl request tendra la siguiente estructura . \\n{ \\n          \"user_name \": \"John Doe \", \\n          \"question \": \"How are you today? \", \\n} \\nLLM \\nUsar un LLM mediante su API para responder las preguntas del usuario.  \\nEs libre de elegir cualquiera que acepte chat y embeddings, Cohere es una opcion gratuita , OpenAI \\nes una opcion paga.  \\nPuede usarse Langchain s i lo desea.', metadata={'source': 'F:\\\\Proyectos\\\\PiConsulting\\\\challenge_rag_llm\\\\docs\\\\challenge_ ai_engineer.pdf', 'page': 0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi_challenge_rag_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
