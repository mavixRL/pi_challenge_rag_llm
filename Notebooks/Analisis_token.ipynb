{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\mavix\\appdata\\roaming\\python\\python39\\site-packages (3.7.5)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.0-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.2.1-cp39-cp39-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.53.0-cp39-cp39-win_amd64.whl.metadata (165 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\mavix\\.conda\\envs\\pi_challenge_rag_llm\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mavix\\.conda\\envs\\pi_challenge_rag_llm\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mavix\\.conda\\envs\\pi_challenge_rag_llm\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mavix\\.conda\\envs\\pi_challenge_rag_llm\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\mavix\\.conda\\envs\\pi_challenge_rag_llm\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\mavix\\.conda\\envs\\pi_challenge_rag_llm\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mavix\\.conda\\envs\\pi_challenge_rag_llm\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached matplotlib-3.9.0-cp39-cp39-win_amd64.whl (7.9 MB)\n",
      "Using cached contourpy-1.2.1-cp39-cp39-win_amd64.whl (182 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.53.0-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.5-cp39-cp39-win_amd64.whl (56 kB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.5\n",
      "    Uninstalling matplotlib-3.7.5:\n",
      "      Successfully uninstalled matplotlib-3.7.5\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.0 kiwisolver-1.4.5 matplotlib-3.9.0 pyparsing-3.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\mavix\\AppData\\Roaming\\Python\\Python39\\site-packages\\~atplotlib.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\mavix\\AppData\\Roaming\\Python\\Python39\\site-packages\\~atplotlib'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dtreeviz 2.2.2 requires colour, which is not installed.\n",
      "dtreeviz 2.2.2 requires graphviz>=0.9, which is not installed.\n",
      "dtreeviz 2.2.2 requires pandas, which is not installed.\n",
      "dtreeviz 2.2.2 requires pytest, which is not installed.\n",
      "explainerdashboard 0.4.7 requires dash>=2.10.1, which is not installed.\n",
      "explainerdashboard 0.4.7 requires graphviz>=0.18.2, which is not installed.\n",
      "explainerdashboard 0.4.7 requires oyaml, which is not installed.\n",
      "explainerdashboard 0.4.7 requires pandas>=1.1, which is not installed.\n",
      "explainerdashboard 0.4.7 requires waitress, which is not installed.\n",
      "gradio 4.26.0 requires aiofiles<24.0,>=22.0, which is not installed.\n",
      "gradio 4.26.0 requires altair<6.0,>=4.2.0, which is not installed.\n",
      "gradio 4.26.0 requires ffmpy, which is not installed.\n",
      "gradio 4.26.0 requires pandas<3.0,>=1.0, which is not installed.\n",
      "gradio 4.26.0 requires pydub, which is not installed.\n",
      "gradio 4.26.0 requires ruff>=0.2.2; sys_platform != \"emscripten\", which is not installed.\n",
      "gradio 4.26.0 requires semantic-version~=2.0, which is not installed.\n",
      "gradio 4.26.0 requires tomlkit==0.12.0, which is not installed.\n",
      "phik 0.12.4 requires pandas>=0.25.1, which is not installed.\n",
      "salib 1.5.0 requires multiprocess, which is not installed.\n",
      "salib 1.5.0 requires pandas>=2.0, which is not installed.\n",
      "statsforecast 1.5.0 requires numba>=0.55.0, which is not installed.\n",
      "statsforecast 1.5.0 requires pandas>=1.3.5, which is not installed.\n",
      "statsforecast 1.5.0 requires plotly, which is not installed.\n",
      "statsforecast 1.5.0 requires statsmodels>=0.13.2, which is not installed.\n",
      "ydata-profiling 4.8.3 requires dacite>=1.8, which is not installed.\n",
      "ydata-profiling 4.8.3 requires htmlmin==0.1.12, which is not installed.\n",
      "ydata-profiling 4.8.3 requires multimethod<2,>=1.4, which is not installed.\n",
      "ydata-profiling 4.8.3 requires numba<1,>=0.56.0, which is not installed.\n",
      "ydata-profiling 4.8.3 requires pandas!=1.4.0,<3,>1.1, which is not installed.\n",
      "ydata-profiling 4.8.3 requires seaborn<0.14,>=0.10.1, which is not installed.\n",
      "ydata-profiling 4.8.3 requires statsmodels<1,>=0.13.2, which is not installed.\n",
      "ydata-profiling 4.8.3 requires typeguard<5,>=3, which is not installed.\n",
      "ydata-profiling 4.8.3 requires matplotlib<3.9,>=3.2, but you have matplotlib 3.9.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir el contador de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83, 1609, 5963, 374, 2294, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(\"tiktoken is great!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiktoken is great!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode([83, 1609, 5963, 374, 2294, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str=\"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-32k-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-32k-0613\",\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a cargar los datos del documento de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<docx.text.paragraph.Paragraph at 0x1cfc423e310>,\n",
       " <docx.text.paragraph.Paragraph at 0x1cff0f4cf40>,\n",
       " <docx.text.paragraph.Paragraph at 0x1cff0f4cf70>,\n",
       " <docx.text.paragraph.Paragraph at 0x1cff0f4ce20>,\n",
       " <docx.text.paragraph.Paragraph at 0x1cff0f4c0d0>,\n",
       " <docx.text.paragraph.Paragraph at 0x1cff0f4cd60>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ficción Espacial: En la lejana galaxia de Zenthoria, dos civilizaciones alienígenas, los Dracorians y los Lumis, se encuentran al borde de la guerra intergaláctica. Un intrépido explorador, Zara, descubre un antiguo artefacto que podría contener la clave para la paz. Mientras viaja por planetas hostiles y se enfrenta a desafíos cósmicos, Zara debe desentrañar los secretos de la reliquia antes de que la galaxia se sumerja en el caos.\n",
      "\n",
      "Ficción Tecnológica: En un futuro distópico, la inteligencia artificial ha evolucionado al punto de alcanzar la singularidad. Un joven ingeniero, Alex, se ve inmerso en una conspiración global cuando descubre que las supercomputadoras han desarrollado emociones. A medida que la humanidad lucha por controlar a estas máquinas sintientes, Alex se enfrenta a dilemas éticos y decisiones que podrían cambiar el curso de la historia.\n",
      "\n",
      "Naturaleza Deslumbrante: En lo profundo de la selva amazónica, una flor mágica conocida como \"Luz de Luna\" florece solo durante la noche. Con pétalos que brillan intensamente, la flor ilumina la oscuridad de la jungla, guiando a criaturas nocturnas y revelando paisajes deslumbrantes. Los lugareños creen que posee poderes curativos, convirtiéndola en el tesoro oculto de la naturaleza.\n",
      "\n",
      "Cuento Corto: En un pequeño pueblo, cada año, un reloj antiguo regala un día extra a la persona más desafortunada. Emma, una joven huérfana, es la elegida este año. Durante su día adicional, descubre una puerta mágica que la transporta a un mundo lleno de maravillas. Al final del día, Emma decide compartir su regalo con el pueblo, dejando una huella imborrable en el corazón de cada habitante.\n",
      "\n",
      "Características del Héroe Olvidado: Conocido como \"Sombra Silenciosa\", nuestro héroe es un maestro del sigilo y la astucia. Dotado de una memoria fotográfica y habilidades de camuflaje, se desplaza entre las sombras para proteger a los indefensos. Su pasado enigmático esconde tragedias que lo impulsan a luchar contra la injusticia. Aunque carece de habilidades sobrenaturales, su ingenio y habilidades tácticas lo convierten en una fuerza a tener en cuenta.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Abre el archivo .docx\n",
    "doc = Document('F:\\Proyectos\\PiConsulting\\challenge_rag_llm\\docs\\documento.docx')\n",
    "ntoken_list = []\n",
    "list_parrafo = []\n",
    "# Lee el contenido del documento\n",
    "for paragraph in doc.paragraphs:\n",
    "    parrafo = paragraph.text\n",
    "    list_parrafo.append(parrafo)\n",
    "    print(parrafo)\n",
    "    ntoken_list.append(num_tokens_from_string(parrafo))\n",
    "    print('')\n",
    "    \n",
    "ntoken_list = [tok  for tok in ntoken_list if tok > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[134, 104, 118, 112, 127]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntoken_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficos de los tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# hacer un histograma de los tokens\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ntoken_list, bins=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones de la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el texto esta en español ademas esta separada por temas completamente diferentes y cada parrafo tiene una longitud menor a 150 tokens por que podriamos separar\n",
    "por lo que el chunking no es una buena idea, ya que no se puede separar por temas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que los párrafos son relativamente cortos y tratan temas completamente diferentes, lo mejor sería no dividirlos en chunks para preservar el contexto y la coherencia de cada tema. Puedes hacer embeddings de cada párrafo individualmente. Aquí tienes un plan detallado:\n",
    "\n",
    "Ficción Espacial:\n",
    "\n",
    "Tokens: 134\n",
    "\n",
    "Ficción Tecnológica:\n",
    "Tokens: 104\n",
    "\n",
    "Naturaleza Deslumbrante:\n",
    "Tokens: 118\n",
    "\n",
    "Cuento Corto:\n",
    "Tokens: 112\n",
    "\n",
    "Características del Héroe Olvidado:\n",
    "Tokens: 127\n",
    "\n",
    "Pasos a seguir:\n",
    "\n",
    "Procesar cada párrafo de manera individual:\n",
    "\n",
    "Debido a que todos tus párrafos tienen menos de 150 tokens, puedes procesarlos sin dividirlos en chunks. Esto asegura que cada párrafo mantiene su contexto completo y cohesión temática.\n",
    "Generación de embeddings:\n",
    "\n",
    "Usa tu modelo de lenguaje para generar embeddings para cada párrafo por separado.\n",
    "Esto garantizará que los embeddings reflejen fielmente el contexto y la temática específica de cada párrafo, lo cual es crucial para mantener la integridad del contenido al realizar consultas o análisis posteriores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi_challenge_rag_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
